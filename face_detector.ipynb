{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h2q27gKz1H20"
      },
      "source": [
        "##### Copyright 2023 The MediaPipe Authors. All Rights Reserved."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "TUfAcER1oUS6"
      },
      "outputs": [],
      "source": [
        "#@title Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "# https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L_cQX8dWu4Dv"
      },
      "source": [
        "# Face Detection with MediaPipe Tasks\n",
        "\n",
        "This notebook shows you how to use the MediaPipe Tasks Python API to detect faces in images."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O6PN9FvIx614"
      },
      "source": [
        "## Preparation\n",
        "\n",
        "Let's start with installing MediaPipe."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "gxbHBsF-8Y_l"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: mediapipe in c:\\users\\the beast\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (0.10.7)Note: you may need to restart the kernel to use updated packages.\n",
            "\n",
            "Requirement already satisfied: absl-py in c:\\users\\the beast\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from mediapipe) (1.4.0)\n",
            "Requirement already satisfied: attrs>=19.1.0 in c:\\users\\the beast\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from mediapipe) (21.4.0)\n",
            "Requirement already satisfied: flatbuffers>=2.0 in c:\\users\\the beast\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from mediapipe) (23.5.26)\n",
            "Requirement already satisfied: matplotlib in c:\\users\\the beast\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from mediapipe) (3.8.1)\n",
            "Requirement already satisfied: numpy in c:\\users\\the beast\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from mediapipe) (1.26.2)\n",
            "Requirement already satisfied: opencv-contrib-python in c:\\users\\the beast\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from mediapipe) (4.8.1.78)\n",
            "Requirement already satisfied: protobuf<4,>=3.11 in c:\\users\\the beast\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from mediapipe) (3.20.3)\n",
            "Requirement already satisfied: sounddevice>=0.4.4 in c:\\users\\the beast\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from mediapipe) (0.4.6)\n",
            "Requirement already satisfied: CFFI>=1.0 in c:\\users\\the beast\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from sounddevice>=0.4.4->mediapipe) (1.15.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\the beast\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib->mediapipe) (1.0.6)\n",
            "Requirement already satisfied: cycler>=0.10 in c:\\users\\the beast\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib->mediapipe) (0.11.0)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\the beast\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib->mediapipe) (4.38.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\the beast\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib->mediapipe) (1.4.4)\n",
            "Requirement already satisfied: packaging>=20.0 in c:\\users\\the beast\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib->mediapipe) (22.0)\n",
            "Requirement already satisfied: pillow>=8 in c:\\users\\the beast\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib->mediapipe) (9.3.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\the beast\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib->mediapipe) (3.1.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\the beast\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib->mediapipe) (2.8.2)\n",
            "Requirement already satisfied: pycparser in c:\\users\\the beast\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from CFFI>=1.0->sounddevice>=0.4.4->mediapipe) (2.21)\n",
            "Requirement already satisfied: six>=1.5 in c:\\users\\the beast\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from python-dateutil>=2.7->matplotlib->mediapipe) (1.16.0)\n"
          ]
        }
      ],
      "source": [
        "%pip install mediapipe"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a49D7h4TVmru"
      },
      "source": [
        "Then download an off-the-shelf model. Check out the [MediaPipe documentation](https://developers.google.com/mediapipe/solutions/vision/face_detector#models) for more face detection models that you can use."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OMjuVQiDYJKF"
      },
      "outputs": [],
      "source": [
        "# %wget -q -O detector.tflite -q https://storage.googleapis.com/mediapipe-models/face_detector/blaze_face_short_range/float16/1/blaze_face_short_range.tflite"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "89BlskiiyGDC"
      },
      "source": [
        "## Visualization utilities"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wLHhoIkkWYLQ"
      },
      "source": [
        "To better demonstrate the Face Detector API, we have created a set of visualization tools that will be used in this colab. These will draw a bounding box around detected faces, as well as markers over certain detected points on the faces."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pyparsing in c:\\users\\the beast\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (3.1.1)\n",
            "Requirement already satisfied: matplotlib in c:\\users\\the beast\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (3.8.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\the beast\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib) (1.0.6)\n",
            "Requirement already satisfied: cycler>=0.10 in c:\\users\\the beast\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib) (0.11.0)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\the beast\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib) (4.38.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\the beast\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib) (1.4.4)\n",
            "Requirement already satisfied: numpy<2,>=1.21 in c:\\users\\the beast\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib) (1.26.2)\n",
            "Requirement already satisfied: packaging>=20.0 in c:\\users\\the beast\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib) (22.0)\n",
            "Requirement already satisfied: pillow>=8 in c:\\users\\the beast\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib) (9.3.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\the beast\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib) (3.1.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\the beast\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in c:\\users\\the beast\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install pyparsing\n",
        "!pip install matplotlib --upgrade"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "H4aPO-hvbw3r"
      },
      "outputs": [],
      "source": [
        "from typing import Tuple, Union\n",
        "import math\n",
        "import cv2\n",
        "import numpy as np\n",
        "import wget\n",
        "\n",
        "path_to_model = \"C:\\\\Users\\\\The Beast\\\\OneDrive\\\\ENSEA\\\\Projet\\\\Models\\\\blaze_face_short_range.tflite\"\n",
        "\n",
        "MARGIN = 10  # pixels\n",
        "ROW_SIZE = 10  # pixels\n",
        "FONT_SIZE = 1\n",
        "FONT_THICKNESS = 1\n",
        "TEXT_COLOR = (255, 0, 0)  # red\n",
        "\n",
        "\n",
        "def _normalized_to_pixel_coordinates(\n",
        "    normalized_x: float, normalized_y: float, image_width: int,\n",
        "    image_height: int) -> Union[None, Tuple[int, int]]:\n",
        "  \"\"\"Converts normalized value pair to pixel coordinates.\"\"\"\n",
        "\n",
        "  # Checks if the float value is between 0 and 1.\n",
        "  def is_valid_normalized_value(value: float) -> bool:\n",
        "    return (value > 0 or math.isclose(0, value)) and (value < 1 or\n",
        "                                                      math.isclose(1, value))\n",
        "\n",
        "  if not (is_valid_normalized_value(normalized_x) and\n",
        "          is_valid_normalized_value(normalized_y)):\n",
        "    # TODO: Draw coordinates even if it's outside of the image bounds.\n",
        "    return None\n",
        "  x_px = min(math.floor(normalized_x * image_width), image_width - 1)\n",
        "  y_px = min(math.floor(normalized_y * image_height), image_height - 1)\n",
        "  return x_px, y_px\n",
        "\n",
        "\n",
        "def visualize(\n",
        "    image,\n",
        "    detection_result\n",
        ") -> np.ndarray:\n",
        "  \"\"\"Draws bounding boxes and keypoints on the input image and return it.\n",
        "  Args:\n",
        "    image: The input RGB image.\n",
        "    detection_result: The list of all \"Detection\" entities to be visualize.\n",
        "  Returns:\n",
        "    Image with bounding boxes.\n",
        "  \"\"\"\n",
        "  annotated_image = image.copy()\n",
        "  height, width, _ = image.shape\n",
        "\n",
        "  for detection in detection_result.detections:\n",
        "    # Draw bounding_box\n",
        "    bbox = detection.bounding_box\n",
        "    start_point = bbox.origin_x, bbox.origin_y\n",
        "    end_point = bbox.origin_x + bbox.width, bbox.origin_y + bbox.height\n",
        "    cv2.rectangle(annotated_image, start_point, end_point, TEXT_COLOR, 3)\n",
        "\n",
        "    # Draw keypoints\n",
        "    for keypoint in detection.keypoints:\n",
        "      keypoint_px = _normalized_to_pixel_coordinates(keypoint.x, keypoint.y,\n",
        "                                                     width, height)\n",
        "      color, thickness, radius = (0, 255, 0), 2, 2\n",
        "      cv2.circle(annotated_image, keypoint_px, thickness, color, radius)\n",
        "\n",
        "    # Draw label and score\n",
        "    category = detection.categories[0]\n",
        "    category_name = category.category_name\n",
        "    category_name = '' if category_name is None else category_name\n",
        "    probability = round(category.score, 2)\n",
        "    result_text = category_name + ' (' + str(probability) + ')'\n",
        "    text_location = (MARGIN + bbox.origin_x,\n",
        "                     MARGIN + ROW_SIZE + bbox.origin_y)\n",
        "    cv2.putText(annotated_image, result_text, text_location, cv2.FONT_HERSHEY_PLAIN,\n",
        "                FONT_SIZE, TEXT_COLOR, FONT_THICKNESS)\n",
        "\n",
        "  return annotated_image"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "83PEJNp9yPBU"
      },
      "source": [
        "## Download test image\n",
        "\n",
        "To demonstrate Face Detection, you can download a sample image using the following code. Credits: https://pixabay.com/photos/brother-sister-girl-family-boy-977170/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "tzXuqyIBlXer"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Saved under my_image (1).jpg\n"
          ]
        }
      ],
      "source": [
        "!py -m wget -o my_image.jpg https://i.imgur.com/Vu2Nqwb.jpg\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "IMAGE_FILE = 'my_image.jpg'\n",
        "\n",
        "import cv2\n",
        "\n",
        "# Show the image\n",
        "image = cv2.imread(IMAGE_FILE)\n",
        "cv2.imshow('hello', image)\n",
        "cv2.waitKey(0)\n",
        "cv2.destroyAllWindows()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NAFQm3HHi5OG"
      },
      "source": [
        "Optionally, you can upload your own image from your computer. To do this, uncomment the following code cell."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Iy4r2_ePylIa"
      },
      "source": [
        "## Running inference and visualizing the results\n",
        "\n",
        "The final step is to run face detection on your selected image. This involves creating your FaceDetector object, loading your image, running detection, and finally, the optional step of displaying the image with visualizations.\n",
        "\n",
        "You can check out the [MediaPipe documentation](https://developers.google.com/mediapipe/solutions/vision/face_detector/python) to learn more about configuration options that this solution supports."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "Yl_Oiye4mUuo"
      },
      "outputs": [],
      "source": [
        "# STEP 1: Import the necessary modules.\n",
        "import numpy as np\n",
        "import mediapipe as mp\n",
        "from mediapipe.tasks import python\n",
        "from mediapipe.tasks.python import vision\n",
        "\n",
        "# STEP 2: Create an FaceDetector object.\n",
        "base_options = python.BaseOptions(model_asset_path=path_to_model)\n",
        "options = vision.FaceDetectorOptions(base_options=base_options)\n",
        "detector = vision.FaceDetector.create_from_options(options)\n",
        "\n",
        "# STEP 3: Load the input image.\n",
        "image = mp.Image.create_from_file(IMAGE_FILE)\n",
        "\n",
        "# STEP 4: Detect faces in the input image.\n",
        "detection_result = detector.detect(image)\n",
        "\n",
        "# STEP 5: Process the detection result. In this case, visualize it.\n",
        "image_copy = np.copy(image.numpy_view())\n",
        "annotated_image = visualize(image_copy, detection_result)\n",
        "rgb_annotated_image = cv2.cvtColor(annotated_image, cv2.COLOR_BGR2RGB)\n",
        "cv2.imshow('The detection', rgb_annotated_image)\n",
        "cv2.waitKey(0)\n",
        "cv2.destroyAllWindows()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "YNJq-ygtZX7J"
      },
      "outputs": [
        {
          "ename": "TypeError",
          "evalue": "__init__(): incompatible constructor arguments. The following argument types are supported:\n    1. mediapipe.python._framework_bindings.image.Image(image_format: mediapipe::ImageFormat_Format, data: numpy.ndarray[numpy.uint8])\n    2. mediapipe.python._framework_bindings.image.Image(image_format: mediapipe::ImageFormat_Format, data: numpy.ndarray[numpy.uint16])\n    3. mediapipe.python._framework_bindings.image.Image(image_format: mediapipe::ImageFormat_Format, data: numpy.ndarray[numpy.float32])\n\nInvoked with: array([[[164, 164, 168],\n        [164, 162, 166],\n        [163, 161, 164],\n        ...,\n        [154, 154, 156],\n        [155, 155, 157],\n        [156, 156, 158]],\n\n       [[162, 162, 164],\n        [162, 160, 163],\n        [162, 160, 163],\n        ...,\n        [156, 155, 155],\n        [157, 156, 156],\n        [158, 157, 157]],\n\n       [[159, 161, 162],\n        [159, 161, 162],\n        [159, 162, 163],\n        ...,\n        [158, 155, 154],\n        [158, 157, 155],\n        [159, 158, 156]],\n\n       ...,\n\n       [[174, 176, 177],\n        [175, 177, 178],\n        [175, 177, 178],\n        ...,\n        [ 73,  59,  69],\n        [ 73,  60,  70],\n        [ 78,  65,  75]],\n\n       [[175, 178, 179],\n        [175, 178, 179],\n        [175, 178, 179],\n        ...,\n        [ 77,  61,  73],\n        [ 77,  61,  74],\n        [ 80,  64,  77]],\n\n       [[175, 177, 178],\n        [175, 177, 178],\n        [175, 177, 178],\n        ...,\n        [ 75,  59,  71],\n        [ 71,  55,  68],\n        [ 76,  60,  73]]], dtype=uint8)",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[1;32mc:\\Users\\The Beast\\OneDrive\\ENSEA\\Projet\\face_detector.ipynb Cell 18\u001b[0m line \u001b[0;36m6\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/The%20Beast/OneDrive/ENSEA/Projet/face_detector.ipynb#X24sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m success, img \u001b[39m=\u001b[39m cap\u001b[39m.\u001b[39mread()\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/The%20Beast/OneDrive/ENSEA/Projet/face_detector.ipynb#X24sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m imgRGB \u001b[39m=\u001b[39m cv2\u001b[39m.\u001b[39mcvtColor(img, cv2\u001b[39m.\u001b[39mCOLOR_BGR2RGB)\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/The%20Beast/OneDrive/ENSEA/Projet/face_detector.ipynb#X24sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m image \u001b[39m=\u001b[39m mp\u001b[39m.\u001b[39;49mImage(imgRGB)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/The%20Beast/OneDrive/ENSEA/Projet/face_detector.ipynb#X24sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m detection_result \u001b[39m=\u001b[39m detector\u001b[39m.\u001b[39mdetect(image)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/The%20Beast/OneDrive/ENSEA/Projet/face_detector.ipynb#X24sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m image_copy \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mcopy(image\u001b[39m.\u001b[39mnumpy_view())\n",
            "\u001b[1;31mTypeError\u001b[0m: __init__(): incompatible constructor arguments. The following argument types are supported:\n    1. mediapipe.python._framework_bindings.image.Image(image_format: mediapipe::ImageFormat_Format, data: numpy.ndarray[numpy.uint8])\n    2. mediapipe.python._framework_bindings.image.Image(image_format: mediapipe::ImageFormat_Format, data: numpy.ndarray[numpy.uint16])\n    3. mediapipe.python._framework_bindings.image.Image(image_format: mediapipe::ImageFormat_Format, data: numpy.ndarray[numpy.float32])\n\nInvoked with: array([[[164, 164, 168],\n        [164, 162, 166],\n        [163, 161, 164],\n        ...,\n        [154, 154, 156],\n        [155, 155, 157],\n        [156, 156, 158]],\n\n       [[162, 162, 164],\n        [162, 160, 163],\n        [162, 160, 163],\n        ...,\n        [156, 155, 155],\n        [157, 156, 156],\n        [158, 157, 157]],\n\n       [[159, 161, 162],\n        [159, 161, 162],\n        [159, 162, 163],\n        ...,\n        [158, 155, 154],\n        [158, 157, 155],\n        [159, 158, 156]],\n\n       ...,\n\n       [[174, 176, 177],\n        [175, 177, 178],\n        [175, 177, 178],\n        ...,\n        [ 73,  59,  69],\n        [ 73,  60,  70],\n        [ 78,  65,  75]],\n\n       [[175, 178, 179],\n        [175, 178, 179],\n        [175, 178, 179],\n        ...,\n        [ 77,  61,  73],\n        [ 77,  61,  74],\n        [ 80,  64,  77]],\n\n       [[175, 177, 178],\n        [175, 177, 178],\n        [175, 177, 178],\n        ...,\n        [ 75,  59,  71],\n        [ 71,  55,  68],\n        [ 76,  60,  73]]], dtype=uint8)"
          ]
        }
      ],
      "source": [
        "cap = cv2.VideoCapture(0)\n",
        "\n",
        "while True:\n",
        "    success, img = cap.read()\n",
        "    imgRGB = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "    image = mp.Image(imgRGB)\n",
        "    detection_result = detector.detect(image)\n",
        "    image_copy = np.copy(image.numpy_view())\n",
        "    annotated_image = visualize(image_copy, detection_result)\n",
        "    rgb_annotated_image = cv2.cvtColor(annotated_image, cv2.COLOR_BGR2RGB)\n",
        "    cv2.imshow('The detection', rgb_annotated_image)\n",
        "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
        "        break\n",
        "    \n",
        "cap.release()\n",
        "cv2.destroyAllWindows()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
